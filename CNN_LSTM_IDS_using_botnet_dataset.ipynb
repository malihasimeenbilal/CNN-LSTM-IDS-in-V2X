{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfNzRpOvmHP3",
        "outputId": "a74c0064-564e-4210-a58b-df9a7a0f2a69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_tJGPptmQ_B",
        "outputId": "84e42dfe-a5f2-4cd7-8b4c-4845b71c74c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Image Processing'\t\t  'Safety Critical System '\n",
            "'Pervasive Computing '\t\t  'security and dependability course '\n",
            "'Project Management - ENGR 5410'  'Software Testing and QA'\n"
          ]
        }
      ],
      "source": [
        "!ls \"/content/drive/Shared drives\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CebVQ4yNmUpD",
        "outputId": "4fd7e0b0-093c-42d2-e75f-e18c5ff9c2c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files in folder:\n",
            "DoS_dataset.csv\n",
            "Botnet-Friday-02-03-2018.csv\n",
            "Bruteforce-Wednesday-14-02-2018.csv\n",
            "DDoS1-Tuesday-20-02-2018.csv\n",
            "DDoS2-Wednesday-21-02-2018.csv\n",
            "DoS1-Thursday-15-02-2018.csv\n",
            "DoS2-Friday-16-02-2018.csv\n",
            "Infil1-Wednesday-28-02-2018.csv\n",
            "Infil2-Thursday-01-03-2018.csv\n",
            "Web1-Thursday-22-02-2018.csv\n",
            "Web2-Friday-23-02-2018.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "base = \"/content/drive/Shared drives/Safety Critical System /dataset\"\n",
        "print(\"Files in folder:\")\n",
        "for f in os.listdir(base):\n",
        "    print(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH49Xdlamavr",
        "outputId": "86f87a1b-4ed2-485e-bb47-1bf8979e1702"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Botnet-Friday-02-03-2018.csv\t     DoS_dataset.csv\n",
            "Bruteforce-Wednesday-14-02-2018.csv  Infil1-Wednesday-28-02-2018.csv\n",
            "DDoS1-Tuesday-20-02-2018.csv\t     Infil2-Thursday-01-03-2018.csv\n",
            "DDoS2-Wednesday-21-02-2018.csv\t     Web1-Thursday-22-02-2018.csv\n",
            "DoS1-Thursday-15-02-2018.csv\t     Web2-Friday-23-02-2018.csv\n",
            "DoS2-Friday-16-02-2018.csv\n"
          ]
        }
      ],
      "source": [
        "!ls \"/content/drive/Shared drives/Safety Critical System /dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "63d903lkmfgz",
        "outputId": "679a5827-660d-4191-c236-6f4cf660ab14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1048575, 80)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ce631e30-70b3-4ef3-9ce4-3715fa350a13\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dst Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Tot Fwd Pkts</th>\n",
              "      <th>Tot Bwd Pkts</th>\n",
              "      <th>TotLen Fwd Pkts</th>\n",
              "      <th>TotLen Bwd Pkts</th>\n",
              "      <th>Fwd Pkt Len Max</th>\n",
              "      <th>Fwd Pkt Len Min</th>\n",
              "      <th>...</th>\n",
              "      <th>Fwd Seg Size Min</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>443</td>\n",
              "      <td>6</td>\n",
              "      <td>02/03/2018 08:47:38</td>\n",
              "      <td>141385</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>553</td>\n",
              "      <td>3773.0</td>\n",
              "      <td>202</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49684</td>\n",
              "      <td>6</td>\n",
              "      <td>02/03/2018 08:47:38</td>\n",
              "      <td>281</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>443</td>\n",
              "      <td>6</td>\n",
              "      <td>02/03/2018 08:47:40</td>\n",
              "      <td>279824</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>1086</td>\n",
              "      <td>10527.0</td>\n",
              "      <td>385</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>443</td>\n",
              "      <td>6</td>\n",
              "      <td>02/03/2018 08:47:40</td>\n",
              "      <td>132</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>443</td>\n",
              "      <td>6</td>\n",
              "      <td>02/03/2018 08:47:41</td>\n",
              "      <td>274016</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>1285</td>\n",
              "      <td>6141.0</td>\n",
              "      <td>517</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 80 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce631e30-70b3-4ef3-9ce4-3715fa350a13')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce631e30-70b3-4ef3-9ce4-3715fa350a13 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce631e30-70b3-4ef3-9ce4-3715fa350a13');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-38b3d4f6-e946-48f5-beeb-3a45bd603af8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38b3d4f6-e946-48f5-beeb-3a45bd603af8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-38b3d4f6-e946-48f5-beeb-3a45bd603af8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Dst Port  Protocol            Timestamp  Flow Duration  Tot Fwd Pkts  \\\n",
              "0       443         6  02/03/2018 08:47:38         141385             9   \n",
              "1     49684         6  02/03/2018 08:47:38            281             2   \n",
              "2       443         6  02/03/2018 08:47:40         279824            11   \n",
              "3       443         6  02/03/2018 08:47:40            132             2   \n",
              "4       443         6  02/03/2018 08:47:41         274016             9   \n",
              "\n",
              "   Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  \\\n",
              "0             7              553           3773.0              202   \n",
              "1             1               38              0.0               38   \n",
              "2            15             1086          10527.0              385   \n",
              "3             0                0              0.0                0   \n",
              "4            13             1285           6141.0              517   \n",
              "\n",
              "   Fwd Pkt Len Min  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n",
              "0                0  ...                20          0.0         0.0   \n",
              "1                0  ...                20          0.0         0.0   \n",
              "2                0  ...                20          0.0         0.0   \n",
              "3                0  ...                20          0.0         0.0   \n",
              "4                0  ...                20          0.0         0.0   \n",
              "\n",
              "   Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min   Label  \n",
              "0         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
              "1         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
              "2         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
              "3         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
              "4         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
              "\n",
              "[5 rows x 80 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "base = \"/content/drive/Shared drives/Safety Critical System /dataset\"\n",
        "fname = \"Botnet-Friday-02-03-2018.csv\"\n",
        "path = os.path.join(base, fname)\n",
        "\n",
        "df = pd.read_csv(path)            # add encoding='latin1' if you get an encoding error\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEgG9gm4mx9Q",
        "outputId": "90597000-e6c5-410c-ff5e-fe6dd6a09150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch 2.8.0+cu126 CUDA: False\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Install (some packages are preinstalled in Colab already)\n",
        "!pip install -q scikit-learn pandas tqdm\n",
        "\n",
        "# Imports\n",
        "import os, time, math, json\n",
        "from collections import Counter\n",
        "import numpy as np, pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "print(\"Torch\", torch.__version__, \"CUDA:\", torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq4HQtKbm5NN",
        "outputId": "baa1205c-4722-4471-c255-b9d82ad2220c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing complete!\n",
            "Features (3D Sequence Shape): (1048566, 10, 79)\n",
            "Labels (Reduced Shape): (1048566,)\n",
            "Sample label distribution: {0.0: 762375, 1.0: 286191}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gc\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# --- CONFIGURATION FOR LSTM ---\n",
        "# IMPORTANT: You must define a sequence length. This is how many previous\n",
        "# network flows/rows the model will look at to predict the current flow.\n",
        "SEQUENCE_LENGTH = 10\n",
        "# ------------------------------\n",
        "\n",
        "# Drop unnamed columns\n",
        "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
        "\n",
        "# Identify label column\n",
        "label_col = None\n",
        "for c in df.columns:\n",
        "    if c.lower() in ['label', 'attack', 'category', 'class']:\n",
        "        label_col = c\n",
        "        break\n",
        "if label_col is None:\n",
        "    raise ValueError(\"No label column found.\")\n",
        "\n",
        "# Separate features and labels\n",
        "y = df[label_col].copy()\n",
        "X = df.drop(label_col, axis=1)\n",
        "del df\n",
        "gc.collect()\n",
        "\n",
        "# Encode categorical columns\n",
        "cat_cols = X.select_dtypes(include=['object']).columns\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    # Note: Using .astype(str) handles potential mixed types or missing values robustly\n",
        "    X[col] = le.fit_transform(X[col].astype(str))\n",
        "\n",
        "# Replace NaNs/Infs\n",
        "X = X.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "# Convert labels to binary (0: Benign, 1: Attack)\n",
        "if y.dtype == 'O':\n",
        "    y = y.apply(lambda x: 0 if x.lower() == 'benign' else 1)\n",
        "y = y.astype(int)\n",
        "\n",
        "# Normalize features (Crucial step before sequencing)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X.values.astype(np.float32))\n",
        "\n",
        "# --- NEW CODE: CONVERT TABULAR DATA TO SEQUENCES FOR LSTM ---\n",
        "\n",
        "def create_sequences(X, y, seq_length):\n",
        "    \"\"\"\n",
        "    Transforms the scaled 2D data into 3D sequences for LSTM.\n",
        "    Each sequence consists of 'seq_length' consecutive samples.\n",
        "    The label corresponds to the last sample in the sequence.\n",
        "    \"\"\"\n",
        "    X_seq, y_seq = [], []\n",
        "    # We iterate until the last index that allows a full sequence of length 'seq_length'\n",
        "    for i in range(len(X) - seq_length + 1):\n",
        "        # Input sequence: samples from i up to i + seq_length\n",
        "        X_seq.append(X[i:i + seq_length])\n",
        "        # Output label: the label of the last sample in that sequence\n",
        "        y_seq.append(y.iloc[i + seq_length - 1])\n",
        "\n",
        "    # Return as NumPy arrays with the new shapes\n",
        "    return np.array(X_seq, dtype=np.float32), np.array(y_seq, dtype=np.float32)\n",
        "\n",
        "\n",
        "# Apply the sequencing function\n",
        "X_seq_np, y_seq_np = create_sequences(X_scaled, y, SEQUENCE_LENGTH)\n",
        "\n",
        "print(\"Preprocessing complete!\")\n",
        "print(f\"Features (3D Sequence Shape): {X_seq_np.shape}\")\n",
        "print(f\"Labels (Reduced Shape): {y_seq_np.shape}\")\n",
        "print(\"Sample label distribution:\", pd.Series(y_seq_np).value_counts().to_dict())\n",
        "\n",
        "# Store the final NumPy arrays to be converted to PyTorch Tensors later\n",
        "X_tensor_source = X_seq_np\n",
        "y_tensor_source = y_seq_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9d8WIfvn-1K",
        "outputId": "3c388f35-e2ea-4cc1-ef75-94d34f9c2d52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Data split — Train: 733996, Val: 157284, Test: 157286\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "\n",
        "# NOTE: X_tensor_source and y_tensor_source were created as NumPy arrays\n",
        "# in the data_preprocessing_lstm.py step.\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# --- CRITICAL CHANGE: Use the sequence-ready NumPy arrays ---\n",
        "# X_tensor_source is 3D (samples, seq_len, features)\n",
        "X_tensor = torch.tensor(X_tensor_source, dtype=torch.float32)\n",
        "\n",
        "# y_tensor_source is 1D (samples), needs to be 2D (samples, 1)\n",
        "y_tensor = torch.tensor(y_tensor_source, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "\n",
        "# The total length of the dataset is now len(X) - SEQUENCE_LENGTH + 1\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "# Use PyTorch's random_split\n",
        "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Note: Batch size should be a factor of the new, reduced dataset size\n",
        "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=256)\n",
        "test_loader = DataLoader(test_ds, batch_size=256)\n",
        "\n",
        "print(f\"Data split — Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKNFJ7c6oKh9",
        "outputId": "a214f16a-4779-473c-83a5-b489ac8b572b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN-LSTM Hybrid Model created. Input Dim: 79, Conv Channels: 64, LSTM Hidden Dim: 128\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# --- HYPERPARAMETERS FOR CNN-LSTM ---\n",
        "# NOTE: input_dim is the number of features in a single flow (X_scaled.shape[1])\n",
        "# We assume this variable is available from the preprocessing step.\n",
        "INPUT_DIM = X_tensor_source.shape[2] # Number of features (channels for Conv1D)\n",
        "SEQUENCE_LENGTH = X_tensor_source.shape[1] # Time steps (length for Conv1D)\n",
        "\n",
        "# CNN Hyperparameters\n",
        "CONV_OUT_CHANNELS = 64 # Number of filters/channels output by the CNN\n",
        "KERNEL_SIZE = 3          # Size of the convolution window (e.g., look at 3 time steps)\n",
        "\n",
        "# LSTM Hyperparameters\n",
        "LSTM_INPUT_DIM = CONV_OUT_CHANNELS # Output of CNN becomes input to LSTM\n",
        "HIDDEN_DIM = 128\n",
        "NUM_LAYERS = 2\n",
        "DROPOUT_RATE = 0.3\n",
        "# ----------------------------------------------------\n",
        "\n",
        "class CNN_LSTM_Net(nn.Module):\n",
        "    \"\"\"\n",
        "    Hybrid CNN-LSTM network for sequence classification.\n",
        "    CNN extracts local features, and LSTM learns temporal dependencies over those features.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, seq_len, conv_out_channels, kernel_size, hidden_dim, num_layers, dropout_rate, num_classes=1):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # 1. CNN Block (Feature Extraction over time dimension)\n",
        "        # Input shape expected: (Batch, Channels=INPUT_DIM, Length=SEQUENCE_LENGTH)\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=input_dim, out_channels=conv_out_channels, kernel_size=kernel_size, padding=(kernel_size - 1) // 2),\n",
        "            nn.BatchNorm1d(conv_out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2) # Downsample the sequence length\n",
        "        )\n",
        "\n",
        "        # Calculate the new sequence length after MaxPool1d\n",
        "        # We assume MaxPool1d halves the length (simplified)\n",
        "        self.new_seq_len = seq_len // 2\n",
        "\n",
        "        # 2. LSTM Block (Temporal Dependency Learning)\n",
        "        # Input to LSTM is (Batch, new_seq_len, conv_out_channels)\n",
        "        self.lstm = nn.LSTM(\n",
        "            conv_out_channels,        # The new feature dimension\n",
        "            hidden_dim,\n",
        "            num_layers,\n",
        "            batch_first=True,         # Input is (batch, sequence_length, features)\n",
        "            dropout=dropout_rate\n",
        "        )\n",
        "\n",
        "        # 3. Final Output Head (Classification)\n",
        "        self.out_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, num_classes)\n",
        "            # CRITICAL: Sigmoid is removed. Use nn.BCEWithLogitsLoss().\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, SEQUENCE_LENGTH, INPUT_DIM)\n",
        "\n",
        "        # --- CNN STEP 1: Permute for Conv1D ---\n",
        "        # Change shape to (Batch, Channels=INPUT_DIM, Length=SEQUENCE_LENGTH)\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        # --- CNN STEP 2: Feature Extraction ---\n",
        "        # x shape: (Batch, CONV_OUT_CHANNELS, NEW_SEQUENCE_LENGTH)\n",
        "        x = self.conv(x)\n",
        "\n",
        "        # --- LSTM STEP 1: Permute back for LSTM ---\n",
        "        # Change shape to (Batch, Sequence_Length=NEW_SEQ_LEN, Features=CONV_OUT_CHANNELS)\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        # --- LSTM STEP 2: Temporal Learning ---\n",
        "        # lstm_out: (batch, new_seq_len, hidden_dim)\n",
        "        # h_n (final hidden state): (num_layers, batch, hidden_dim)\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "\n",
        "        # Extract the hidden state from the LAST layer (h_n[-1])\n",
        "        # This state summarizes the entire sequence for the final prediction.\n",
        "        final_h = h_n[-1] # shape: (batch_size, hidden_dim)\n",
        "\n",
        "        # --- DENSE HEAD: Classification ---\n",
        "        logits = self.out_head(final_h)\n",
        "\n",
        "        return logits\n",
        "\n",
        "# Instantiate the new CNN-LSTM model\n",
        "model = CNN_LSTM_Net(\n",
        "    input_dim=INPUT_DIM,\n",
        "    seq_len=SEQUENCE_LENGTH,\n",
        "    conv_out_channels=CONV_OUT_CHANNELS,\n",
        "    kernel_size=KERNEL_SIZE,\n",
        "    hidden_dim=HIDDEN_DIM,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dropout_rate=DROPOUT_RATE\n",
        ").to(device)\n",
        "\n",
        "print(f\"CNN-LSTM Hybrid Model created. Input Dim: {INPUT_DIM}, Conv Channels: {CONV_OUT_CHANNELS}, LSTM Hidden Dim: {HIDDEN_DIM}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq-zZunEzs2V",
        "outputId": "550e60c4-2735-4538-851d-53ff8fa4bf90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_LSTM_Net(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv1d(79, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (lstm): LSTM(64, 128, num_layers=2, batch_first=True, dropout=0.3)\n",
            "  (out_head): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=64, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Criterion changed to: BCEWithLogitsLoss\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# --- Import Hyperparameters and Model Class ---\n",
        "# We assume the hyperparameters (INPUT_DIM, SEQUENCE_LENGTH, CONV_OUT_CHANNELS, etc.)\n",
        "# and the CNN_LSTM_Net class are available from the previously run 'lstm_model.py'.\n",
        "\n",
        "# --- Instantiate the CNN-LSTM Hybrid Model ---\n",
        "# The model instantiation now uses the required sequential hyperparameters.\n",
        "model = CNN_LSTM_Net(\n",
        "    input_dim=INPUT_DIM,\n",
        "    seq_len=SEQUENCE_LENGTH,\n",
        "    conv_out_channels=CONV_OUT_CHANNELS,\n",
        "    kernel_size=KERNEL_SIZE,\n",
        "    hidden_dim=HIDDEN_DIM,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dropout_rate=DROPOUT_RATE\n",
        ").to(device)\n",
        "\n",
        "# --- CRITICAL CHANGE: Update Loss Function ---\n",
        "# Since the CNN_LSTM_Net output does not have a Sigmoid layer, we must use\n",
        "# BCEWithLogitsLoss for numerical stability.\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0007)\n",
        "\n",
        "print(model)\n",
        "print(f\"Criterion changed to: {type(criterion).__name__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN_XreIpoRH0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Note: 'criterion' and 'device' are assumed to be defined globally\n",
        "# (criterion is nn.BCEWithLogitsLoss())\n",
        "\n",
        "def fgsm_attack(model, X, y, epsilon):\n",
        "    \"\"\"\n",
        "    Performs the Fast Gradient Sign Method (FGSM) attack.\n",
        "    X, y are the batch of sequences and labels (3D input for X).\n",
        "    \"\"\"\n",
        "    # Clone and detach the original input\n",
        "    X_orig = X.clone().detach().to(device)\n",
        "    X_adv = X_orig.clone()\n",
        "\n",
        "    # Enable gradient tracking on the adversarial sample\n",
        "    X_adv.requires_grad = True\n",
        "\n",
        "    # Forward pass and loss calculation\n",
        "    outputs = model(X_adv)\n",
        "    loss = criterion(outputs, y)\n",
        "\n",
        "    # Backpropagate to compute the gradient\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Apply the perturbation: Add epsilon * sign(gradient)\n",
        "    X_adv = X_adv + epsilon * X_adv.grad.sign()\n",
        "\n",
        "    # CRITICAL: Constrain the perturbed sample (X_adv) to be within\n",
        "    # the L-infinity ball centered at the original sample (X_orig).\n",
        "    # This ensures |X_adv - X_orig| <= epsilon.\n",
        "    perturb = torch.clamp(X_adv - X_orig, min=-epsilon, max=epsilon)\n",
        "    X_adv = (X_orig + perturb).detach()\n",
        "\n",
        "    # NOTE: The previous clamp to [0.0, 1.0] is removed because\n",
        "    # StandardScaler data is unbounded (e.g., [-3, 3]).\n",
        "\n",
        "    return X_adv\n",
        "\n",
        "def pgd_attack(model, X, y, epsilon=0.1, alpha=0.01, iters=10):\n",
        "    \"\"\"\n",
        "    Performs the Projected Gradient Descent (PGD) attack (iterative FGSM).\n",
        "    \"\"\"\n",
        "    X_orig = X.clone().detach().to(device)\n",
        "\n",
        "    # Initialize adversarial sample randomly within the epsilon ball\n",
        "    X_adv = X_orig + torch.empty_like(X_orig).uniform_(-epsilon, epsilon).to(device)\n",
        "\n",
        "    # Ensure initialization is constrained by the epsilon ball\n",
        "    perturb = torch.clamp(X_adv - X_orig, min=-epsilon, max=epsilon)\n",
        "    X_adv = X_orig + perturb\n",
        "\n",
        "    # Start the iterative attack\n",
        "    for _ in range(iters):\n",
        "        X_adv = X_adv.detach()\n",
        "        X_adv.requires_grad = True\n",
        "\n",
        "        outputs = model(X_adv)\n",
        "        loss = criterion(outputs, y)\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # PGD Step: Apply gradient sign scaled by alpha\n",
        "        X_adv = X_adv + alpha * X_adv.grad.sign()\n",
        "\n",
        "        # Projection Step: Project back to L-infinity ball around X_orig\n",
        "        perturb = torch.clamp(X_adv - X_orig, min=-epsilon, max=epsilon)\n",
        "        X_adv = X_orig + perturb\n",
        "\n",
        "    return X_adv.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_Uu9Q-RoWiE"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Note: The following variables/functions are assumed to be defined globally:\n",
        "# model, device, criterion (nn.BCEWithLogitsLoss), fgsm_attack, pgd_attack.\n",
        "\n",
        "def get_metrics_from_arrays(labels, preds_binary, preds_proba):\n",
        "    \"\"\"Calculates a comprehensive set of metrics for binary classification.\"\"\"\n",
        "    # Ensure all inputs are numpy arrays\n",
        "    labels = np.array(labels)\n",
        "    preds_binary = np.array(preds_binary)\n",
        "    preds_proba = np.array(preds_proba)\n",
        "\n",
        "    # Calculate ROC AUC, handling ValueError if only one class is present\n",
        "    try:\n",
        "        roc_auc = roc_auc_score(labels, preds_proba)\n",
        "    except ValueError:\n",
        "        roc_auc = 0.5 # Default to 0.5 if only one class is present in the test batch\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, preds_binary),\n",
        "        \"f1\": f1_score(labels, preds_binary, zero_division=0),\n",
        "        \"precision\": precision_score(labels, preds_binary, zero_division=0),\n",
        "        \"recall\": recall_score(labels, preds_binary, zero_division=0),\n",
        "        \"roc_auc\": roc_auc\n",
        "    }\n",
        "\n",
        "\n",
        "def evaluate_clean(model, dataloader):\n",
        "    \"\"\"Evaluates the model on clean (unperturbed) data.\"\"\"\n",
        "    model.eval()\n",
        "    all_preds_binary, all_labels, all_probs = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in dataloader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(xb)\n",
        "            probs = torch.sigmoid(logits)\n",
        "\n",
        "            # Convert probabilities to binary predictions\n",
        "            preds_binary = (probs > 0.5).int()\n",
        "\n",
        "            # Collect results\n",
        "            all_probs.extend(probs.cpu().numpy().reshape(-1))\n",
        "            all_preds_binary.extend(preds_binary.cpu().numpy().reshape(-1))\n",
        "            all_labels.extend(yb.cpu().numpy().reshape(-1))\n",
        "\n",
        "    return get_metrics_from_arrays(all_labels, all_preds_binary, all_probs)\n",
        "\n",
        "\n",
        "def evaluate_fgsm(model, dataloader, epsilon):\n",
        "    \"\"\"Evaluates the model under FGSM attack.\"\"\"\n",
        "    model.eval()\n",
        "    all_preds_binary, all_labels, all_probs = [], [], []\n",
        "\n",
        "    # Loop over batches (no torch.no_grad() here, as attack needs gradients)\n",
        "    for xb, yb in dataloader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "        # 1. Generate adversarial examples\n",
        "        # fgsm_attack handles the required gradient step\n",
        "        xb_adv = fgsm_attack(model, xb, yb, epsilon)\n",
        "\n",
        "        # 2. Evaluate model on adversarial examples (use no_grad for evaluation)\n",
        "        with torch.no_grad():\n",
        "            logits = model(xb_adv)\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds_binary = (probs > 0.5).int()\n",
        "\n",
        "            all_probs.extend(probs.cpu().numpy().reshape(-1))\n",
        "            all_preds_binary.extend(preds_binary.cpu().numpy().reshape(-1))\n",
        "            all_labels.extend(yb.cpu().numpy().reshape(-1))\n",
        "\n",
        "    return get_metrics_from_arrays(all_labels, all_preds_binary, all_probs)\n",
        "\n",
        "\n",
        "def evaluate_pgd(model, dataloader, epsilon, alpha, iters):\n",
        "    \"\"\"Evaluates the model under PGD attack.\"\"\"\n",
        "    model.eval()\n",
        "    all_preds_binary, all_labels, all_probs = [], [], []\n",
        "\n",
        "    # Loop over batches (no torch.no_grad() here, as attack needs gradients)\n",
        "    for xb, yb in dataloader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "        # 1. Generate adversarial examples\n",
        "        # pgd_attack handles the required iterative gradient steps\n",
        "        xb_adv = pgd_attack(model, xb, yb, epsilon, alpha, iters)\n",
        "\n",
        "        # 2. Evaluate model on adversarial examples (use no_grad for evaluation)\n",
        "        with torch.no_grad():\n",
        "            logits = model(xb_adv)\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds_binary = (probs > 0.5).int()\n",
        "\n",
        "            all_probs.extend(probs.cpu().numpy().reshape(-1))\n",
        "            all_preds_binary.extend(preds_binary.cpu().numpy().reshape(-1))\n",
        "            all_labels.extend(yb.cpu().numpy().reshape(-1))\n",
        "\n",
        "    return get_metrics_from_arrays(all_labels, all_preds_binary, all_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_0tQ7rW3dG4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Note: 'model', 'optimizer', 'criterion', 'device', and 'fgsm_attack'\n",
        "# are assumed to be defined globally.\n",
        "\n",
        "def train_one_epoch_adv(model, dataloader, optimizer, criterion, epsilon=0.05):\n",
        "    \"\"\"\n",
        "    Performs one epoch of training using Adversarial Training (AT).\n",
        "    AT uses a combination of clean loss and adversarial loss (FGSM).\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    # Iterate over the 3D sequence batches\n",
        "    for xb, yb in dataloader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 1. Calculate Clean Loss\n",
        "        logits_clean = model(xb)\n",
        "        loss_clean = criterion(logits_clean, yb)\n",
        "\n",
        "        # 2. Generate Adversarial Example (FGSM)\n",
        "        # The fgsm_attack uses the current state of the model to generate the perturbation.\n",
        "        xb_adv = fgsm_attack(model, xb, yb, epsilon)\n",
        "\n",
        "        # 3. Calculate Adversarial Loss\n",
        "        # Ensure the model is evaluated on the newly generated adversarial sample.\n",
        "        logits_adv = model(xb_adv)\n",
        "        loss_adv = criterion(logits_adv, yb)\n",
        "\n",
        "        # 4. Combined Loss (Weighting clean and adversarial components)\n",
        "        # This trains the model to be robust against both clean and perturbed data.\n",
        "        loss = 0.5 * loss_clean + 0.5 * loss_adv\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate loss (scaled by batch size)\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "\n",
        "    # Return average loss per sample across the entire epoch\n",
        "    return total_loss / len(dataloader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsOGtrYd3hb1",
        "outputId": "e38799c4-8943-4571-96e6-ab49dae2cdf4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 1 Results ---\n",
            "Loss: 0.0088\n",
            "Clean Acc: 0.9998 | FGSM Acc: 0.9997 | PGD Acc: 0.9997\n",
            "\n",
            "[ Clean Metrics ]\n",
            "  F1: 0.9996 | Precision: 1.0000 | Recall: 0.9992 | AUC: 1.0000\n",
            "\n",
            "[ FGSM Metrics (Epsilon={epsilon_train}) ]\n",
            "  F1: 0.9995 | Precision: 0.9999 | Recall: 0.9990 | AUC: 1.0000\n",
            "\n",
            "[ PGD Metrics (Epsilon=0.05) ]\n",
            "  F1: 0.9995 | Precision: 0.9999 | Recall: 0.9990 | AUC: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 2 Results ---\n",
            "Loss: 0.0012\n",
            "Clean Acc: 0.9999 | FGSM Acc: 0.9998 | PGD Acc: 0.9998\n",
            "\n",
            "[ Clean Metrics ]\n",
            "  F1: 0.9998 | Precision: 0.9999 | Recall: 0.9998 | AUC: 1.0000\n",
            "\n",
            "[ FGSM Metrics (Epsilon={epsilon_train}) ]\n",
            "  F1: 0.9997 | Precision: 0.9998 | Recall: 0.9995 | AUC: 1.0000\n",
            "\n",
            "[ PGD Metrics (Epsilon=0.05) ]\n",
            "  F1: 0.9997 | Precision: 0.9998 | Recall: 0.9996 | AUC: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 3 Results ---\n",
            "Loss: 0.0008\n",
            "Clean Acc: 0.9999 | FGSM Acc: 0.9998 | PGD Acc: 0.9998\n",
            "\n",
            "[ Clean Metrics ]\n",
            "  F1: 0.9998 | Precision: 0.9999 | Recall: 0.9996 | AUC: 1.0000\n",
            "\n",
            "[ FGSM Metrics (Epsilon={epsilon_train}) ]\n",
            "  F1: 0.9997 | Precision: 0.9999 | Recall: 0.9996 | AUC: 1.0000\n",
            "\n",
            "[ PGD Metrics (Epsilon=0.05) ]\n",
            "  F1: 0.9997 | Precision: 0.9999 | Recall: 0.9996 | AUC: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 4 Results ---\n",
            "Loss: 0.0007\n",
            "Clean Acc: 0.9999 | FGSM Acc: 0.9999 | PGD Acc: 0.9999\n",
            "\n",
            "[ Clean Metrics ]\n",
            "  F1: 0.9998 | Precision: 0.9999 | Recall: 0.9998 | AUC: 1.0000\n",
            "\n",
            "[ FGSM Metrics (Epsilon={epsilon_train}) ]\n",
            "  F1: 0.9998 | Precision: 0.9998 | Recall: 0.9997 | AUC: 1.0000\n",
            "\n",
            "[ PGD Metrics (Epsilon=0.05) ]\n",
            "  F1: 0.9998 | Precision: 0.9999 | Recall: 0.9997 | AUC: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 5 Results ---\n",
            "Loss: 0.0006\n",
            "Clean Acc: 0.9999 | FGSM Acc: 0.9999 | PGD Acc: 0.9999\n",
            "\n",
            "[ Clean Metrics ]\n",
            "  F1: 0.9999 | Precision: 1.0000 | Recall: 0.9998 | AUC: 1.0000\n",
            "\n",
            "[ FGSM Metrics (Epsilon={epsilon_train}) ]\n",
            "  F1: 0.9998 | Precision: 1.0000 | Recall: 0.9997 | AUC: 1.0000\n",
            "\n",
            "[ PGD Metrics (Epsilon=0.05) ]\n",
            "  F1: 0.9998 | Precision: 1.0000 | Recall: 0.9997 | AUC: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 6 Results ---\n",
            "Loss: 0.0005\n",
            "Clean Acc: 0.9999 | FGSM Acc: 0.9999 | PGD Acc: 0.9999\n",
            "\n",
            "[ Clean Metrics ]\n",
            "  F1: 0.9999 | Precision: 1.0000 | Recall: 0.9998 | AUC: 1.0000\n",
            "\n",
            "[ FGSM Metrics (Epsilon={epsilon_train}) ]\n",
            "  F1: 0.9998 | Precision: 0.9999 | Recall: 0.9997 | AUC: 1.0000\n",
            "\n",
            "[ PGD Metrics (Epsilon=0.05) ]\n",
            "  F1: 0.9998 | Precision: 0.9999 | Recall: 0.9998 | AUC: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 7 Results ---\n",
            "Loss: 0.0004\n",
            "Clean Acc: 0.9999 | FGSM Acc: 0.9999 | PGD Acc: 0.9999\n",
            "\n",
            "[ Clean Metrics ]\n",
            "  F1: 0.9999 | Precision: 1.0000 | Recall: 0.9999 | AUC: 1.0000\n",
            "\n",
            "[ FGSM Metrics (Epsilon={epsilon_train}) ]\n",
            "  F1: 0.9999 | Precision: 0.9999 | Recall: 0.9998 | AUC: 1.0000\n",
            "\n",
            "[ PGD Metrics (Epsilon=0.05) ]\n",
            "  F1: 0.9999 | Precision: 0.9999 | Recall: 0.9998 | AUC: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 8 Results ---\n",
            "Loss: 0.0004\n",
            "Clean Acc: 1.0000 | FGSM Acc: 0.9999 | PGD Acc: 0.9999\n",
            "\n",
            "[ Clean Metrics ]\n",
            "  F1: 0.9999 | Precision: 1.0000 | Recall: 0.9999 | AUC: 1.0000\n",
            "\n",
            "[ FGSM Metrics (Epsilon={epsilon_train}) ]\n",
            "  F1: 0.9999 | Precision: 0.9999 | Recall: 0.9998 | AUC: 1.0000\n",
            "\n",
            "[ PGD Metrics (Epsilon=0.05) ]\n",
            "  F1: 0.9999 | Precision: 0.9999 | Recall: 0.9998 | AUC: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 9 Results ---\n",
            "Loss: 0.0003\n",
            "Clean Acc: 0.9999 | FGSM Acc: 0.9999 | PGD Acc: 0.9999\n",
            "\n",
            "[ Clean Metrics ]\n",
            "  F1: 0.9998 | Precision: 1.0000 | Recall: 0.9997 | AUC: 1.0000\n",
            "\n",
            "[ FGSM Metrics (Epsilon={epsilon_train}) ]\n",
            "  F1: 0.9998 | Precision: 0.9999 | Recall: 0.9997 | AUC: 1.0000\n",
            "\n",
            "[ PGD Metrics (Epsilon=0.05) ]\n",
            "  F1: 0.9998 | Precision: 0.9999 | Recall: 0.9997 | AUC: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 10 Results ---\n",
            "Loss: 0.0003\n",
            "Clean Acc: 0.9999 | FGSM Acc: 0.9999 | PGD Acc: 0.9999\n",
            "\n",
            "[ Clean Metrics ]\n",
            "  F1: 0.9999 | Precision: 1.0000 | Recall: 0.9998 | AUC: 1.0000\n",
            "\n",
            "[ FGSM Metrics (Epsilon={epsilon_train}) ]\n",
            "  F1: 0.9998 | Precision: 0.9999 | Recall: 0.9998 | AUC: 1.0000\n",
            "\n",
            "[ PGD Metrics (Epsilon=0.05) ]\n",
            "  F1: 0.9998 | Precision: 0.9999 | Recall: 0.9998 | AUC: 1.0000\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Note: model, train_loader, test_loader, optimizer, criterion, device,\n",
        "# fgsm_attack, evaluate_clean, evaluate_fgsm, and evaluate_pgd are assumed\n",
        "# to be defined from previous cells.\n",
        "\n",
        "epochs = 10      # 10 epochs\n",
        "epsilon_train = 0.05 # Epsilon used for training FGSM attack\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    num_samples = 0\n",
        "\n",
        "    # Training Loop\n",
        "    for xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch} Training\", leave=False):\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        num_samples += xb.size(0)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 1. Clean loss\n",
        "        logits_clean = model(xb)\n",
        "        loss_clean = criterion(logits_clean, yb)\n",
        "\n",
        "        # 2. Adversarial loss (FGSM)\n",
        "        # We ensure the attack functions correctly use the 3D sequential input\n",
        "        xb_adv = fgsm_attack(model, xb, yb, epsilon_train)\n",
        "        logits_adv = model(xb_adv)\n",
        "        loss_adv = criterion(logits_adv, yb)\n",
        "\n",
        "        # 3. Combined loss\n",
        "        loss = 0.5 * loss_clean + 0.5 * loss_adv\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "\n",
        "    avg_loss = total_loss / num_samples\n",
        "\n",
        "    # Evaluation after epoch (Model is implicitly set to .eval() inside the functions)\n",
        "\n",
        "    # CRITICAL CHANGE: Store the full metrics dictionary\n",
        "    metrics_clean = evaluate_clean(model, test_loader)\n",
        "    metrics_fgsm = evaluate_fgsm(model, test_loader, epsilon=epsilon_train)\n",
        "    metrics_pgd = evaluate_pgd(model, test_loader, epsilon=0.05, alpha=0.01, iters=5)\n",
        "\n",
        "    # Print summary of results (Accessing 'accuracy' from the dictionary)\n",
        "    print(f\"\\n--- Epoch {epoch} Results ---\")\n",
        "    print(f\"Loss: {avg_loss:.4f}\")\n",
        "    print(f\"Clean Acc: {metrics_clean['accuracy']:.4f} | FGSM Acc: {metrics_fgsm['accuracy']:.4f} | PGD Acc: {metrics_pgd['accuracy']:.4f}\")\n",
        "\n",
        "    # Print additional metrics for detailed robustness analysis\n",
        "    print(\"\\n[ Clean Metrics ]\")\n",
        "    print(f\"  F1: {metrics_clean['f1']:.4f} | Precision: {metrics_clean['precision']:.4f} | Recall: {metrics_clean['recall']:.4f} | AUC: {metrics_clean['roc_auc']:.4f}\")\n",
        "\n",
        "    print(\"\\n[ FGSM Metrics (Epsilon={epsilon_train}) ]\")\n",
        "    print(f\"  F1: {metrics_fgsm['f1']:.4f} | Precision: {metrics_fgsm['precision']:.4f} | Recall: {metrics_fgsm['recall']:.4f} | AUC: {metrics_fgsm['roc_auc']:.4f}\")\n",
        "\n",
        "    print(\"\\n[ PGD Metrics (Epsilon=0.05) ]\")\n",
        "    print(f\"  F1: {metrics_pgd['f1']:.4f} | Precision: {metrics_pgd['precision']:.4f} | Recall: {metrics_pgd['recall']:.4f} | AUC: {metrics_pgd['roc_auc']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MnWS9-Gio5YJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfa0JfV50q3B"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Note: model, train_loader, test_loader, optimizer, criterion, device,\n",
        "# fgsm_attack, evaluate_clean, evaluate_fgsm, and evaluate_pgd are assumed\n",
        "# to be defined from previous cells.\n",
        "\n",
        "# Re-define train_one_epoch_adv here to ensure it is runnable, though\n",
        "# it should already be defined in training_loop.py\n",
        "def train_one_epoch_adv(model, dataloader, optimizer, criterion, epsilon=0.05):\n",
        "    \"\"\"\n",
        "    Performs one epoch of training using Adversarial Training (AT).\n",
        "    (Copied from training_loop.py for self-contained execution)\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for xb, yb in dataloader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits_clean = model(xb)\n",
        "        loss_clean = criterion(logits_clean, yb)\n",
        "\n",
        "        # Ensure fgsm_attack is defined and available (assumed from attack_functions.py)\n",
        "        # Note: This requires fgsm_attack to be globally available or imported.\n",
        "        xb_adv = fgsm_attack(model, xb, yb, epsilon)\n",
        "        logits_adv = model(xb_adv)\n",
        "        loss_adv = criterion(logits_adv, yb)\n",
        "\n",
        "        loss = 0.5 * loss_clean + 0.5 * loss_adv\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "    return total_loss / len(dataloader.dataset)\n",
        "\n",
        "\n",
        "# --- MAIN TRAINING AND EVALUATION LOOP ---\n",
        "\n",
        "epochs = 10      # 10 epochs\n",
        "epsilon_train = 0.05 # Epsilon used for training FGSM attack\n",
        "\n",
        "print(\"Starting Adversarial Training...\")\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    num_samples = 0\n",
        "\n",
        "    # Training Loop using the defined function\n",
        "    for xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch} Training\", leave=False):\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        num_samples += xb.size(0)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 1. Clean loss\n",
        "        logits_clean = model(xb)\n",
        "        loss_clean = criterion(logits_clean, yb)\n",
        "\n",
        "        # 2. Adversarial loss (FGSM)\n",
        "        xb_adv = fgsm_attack(model, xb, yb, epsilon_train)\n",
        "        logits_adv = model(xb_adv)\n",
        "        loss_adv = criterion(logits_adv, yb)\n",
        "\n",
        "        # 3. Combined loss\n",
        "        loss = 0.5 * loss_clean + 0.5 * loss_adv\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "\n",
        "    avg_loss = total_loss / num_samples\n",
        "\n",
        "    # Evaluation after epoch\n",
        "    metrics_clean = evaluate_clean(model, test_loader)\n",
        "    metrics_fgsm = evaluate_fgsm(model, test_loader, epsilon=epsilon_train)\n",
        "    metrics_pgd = evaluate_pgd(model, test_loader, epsilon=0.05, alpha=0.01, iters=5)\n",
        "\n",
        "    print(f\"\\n--- Epoch {epoch} Results ---\")\n",
        "    print(f\"Loss: {avg_loss:.4f}\")\n",
        "    print(f\"Clean Acc: {metrics_clean['accuracy']:.4f} | FGSM Acc: {metrics_fgsm['accuracy']:.4f} | PGD Acc: {metrics_pgd['accuracy']:.4f}\")\n",
        "\n",
        "    print(\"\\n[ Clean Metrics ]\")\n",
        "    print(f\"  F1: {metrics_clean['f1']:.4f} | Precision: {metrics_clean['precision']:.4f} | Recall: {metrics_clean['recall']:.4f} | AUC: {metrics_clean['roc_auc']:.4f}\")\n",
        "\n",
        "    print(\"\\n[ FGSM Metrics (Epsilon={epsilon_train}) ]\")\n",
        "    print(f\"  F1: {metrics_fgsm['f1']:.4f} | Precision: {metrics_fgsm['precision']:.4f} | Recall: {metrics_fgsm['recall']:.4f} | AUC: {metrics_fgsm['roc_auc']:.4f}\")\n",
        "\n",
        "    print(\"\\n[ PGD Metrics (Epsilon=0.05) ]\")\n",
        "    print(f\"  F1: {metrics_pgd['f1']:.4f} | Precision: {metrics_pgd['precision']:.4f} | Recall: {metrics_pgd['recall']:.4f} | AUC: {metrics_pgd['roc_auc']:.4f}\")\n",
        "\n",
        "# --- ROBUSTNESS CURVE GENERATION ---\n",
        "\n",
        "print(\"\\n\\n--- Generating Robustness Curve (Sweeping Epsilon) ---\")\n",
        "\n",
        "# 1. Define the range of attack intensities (Epsilons)\n",
        "epsilons_to_test = np.linspace(0.0, 0.35, num=10).round(4).tolist()\n",
        "\n",
        "fgsm_accuracies = []\n",
        "pgd_accuracies = []\n",
        "\n",
        "# 2. Sweep through the epsilon values for FGSM\n",
        "print(\"Evaluating FGSM...\")\n",
        "for eps in tqdm(epsilons_to_test, desc=\"FGSM Sweep\", leave=False):\n",
        "    # evaluate_fgsm returns a dictionary, we extract the accuracy\n",
        "    metrics = evaluate_fgsm(model, test_loader, epsilon=eps)\n",
        "    fgsm_accuracies.append(metrics['accuracy'])\n",
        "\n",
        "# 3. Sweep through the epsilon values for PGD\n",
        "print(\"Evaluating PGD...\")\n",
        "alpha_pgd = 0.01\n",
        "iters_pgd = 5\n",
        "for eps in tqdm(epsilons_to_test, desc=\"PGD Sweep\", leave=False):\n",
        "    # evaluate_pgd returns a dictionary, we extract the accuracy\n",
        "    metrics = evaluate_pgd(model, test_loader, epsilon=eps, alpha=alpha_pgd, iters=iters_pgd)\n",
        "    pgd_accuracies.append(metrics['accuracy'])\n",
        "\n",
        "# 4. Plot the Robustness Curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot FGSM results\n",
        "plt.plot(epsilons_to_test, fgsm_accuracies, marker='o', linestyle='-', label='FGSM Accuracy')\n",
        "\n",
        "# Plot PGD results\n",
        "plt.plot(epsilons_to_test, pgd_accuracies, marker='x', linestyle='--', label=f'PGD Accuracy (α={alpha_pgd}, iters={iters_pgd})')\n",
        "\n",
        "plt.title('Robustness Curve: Accuracy vs. Attack Intensity ($\\epsilon$)', fontsize=14)\n",
        "plt.xlabel('Epsilon ($\\epsilon$) - Attack Strength', fontsize=12)\n",
        "plt.ylabel('Accuracy', fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=':', alpha=0.6)\n",
        "plt.xlim([0, max(epsilons_to_test)])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nRobustness Curve Plot Displayed.\")\n",
        "\n",
        "# --- Single Evaluation Example (Verification) ---\n",
        "results_clean = evaluate_clean(model, test_loader)\n",
        "results_fgsm = evaluate_fgsm(model, test_loader, epsilon=0.05)\n",
        "results_pgd = evaluate_pgd(model, test_loader, epsilon=0.05, alpha=0.01, iters=5)\n",
        "\n",
        "print(\"\\n✅ Final Model Evaluation:\")\n",
        "print(f\"Clean Acc: {results_clean['accuracy']:.4f} | F1: {results_clean['f1']:.4f}\")\n",
        "print(f\"FGSM Attack (ε=0.05) Acc: {results_fgsm['accuracy']:.4f} | F1: {results_fgsm['f1']:.4f}\")\n",
        "print(f\"PGD Attack (ε=0.05) Acc: {results_pgd['accuracy']:.4f} | F1: {results_pgd['f1']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7Cygzad_6pfA"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# eps_list = [0.01, 0.05, 0.1, 0.2]\n",
        "# fgsm_results = [evaluate_fgsm(model, test_loader, eps) for eps in eps_list]\n",
        "\n",
        "# plt.figure(figsize=(6,4))\n",
        "# plt.plot(eps_list, fgsm_results, marker='o')\n",
        "# plt.title(\"FGSM Attack Impact on Model Accuracy\")\n",
        "# plt.xlabel(\"Epsilon (ε)\")\n",
        "# plt.ylabel(\"Accuracy\")\n",
        "# plt.grid(True)\n",
        "# plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxkuNftCQWdR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Save the state dictionary of the adversarially trained CNN-LSTM model\n",
        "# The file name reflects the model type (CNN-LSTM), application (IDS),\n",
        "# and training method (adv_trained).\n",
        "torch.save(model.state_dict(), \"cnn_lstm_ids_adv_trained.pth\")\n",
        "print(\"Model state dictionary saved successfully to cnn_lstm_ids_adv_trained.pth\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}